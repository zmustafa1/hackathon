# -*- coding: utf-8 -*-
"""remoteHacking_Preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w2fGgFxIxbu08K__SRd8ChyOfp7LMuL1
"""

!pip install duration

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import datetime
from duration import (
    to_iso8601,
    to_seconds,
    to_timedelta,
    to_tuple,
)
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from collections import Counter
from imblearn.under_sampling import ClusterCentroids
from imblearn.under_sampling import RandomUnderSampler
from google.colab import drive

drive.mount('/content/drive')

df=pd.read_csv('/content/drive/My Drive/Remote Hacking/Status_2016-01-01_-_2020-03-01.csv',sep=';')
s1617=pd.read_csv('/content/drive/My Drive/Remote Hacking/Turbine_Data_2016-01-01_-_2017-12-31.csv', sep=';', decimal=",")
s1820=pd.read_csv('/content/drive/My Drive/Remote Hacking/Turbine_Data_2018-01-01_-_2020-03-01.csv', sep=';', decimal=".")

sensor=pd.concat([s1617, s1820], ignore_index=True)
sensor.index=pd.to_datetime(sensor['# Date and time'])

"""
pa18,pa20,pa22,pa23,pa24 = pd.DataFrame(),pd.DataFrame(),pd.DataFrame(),pd.DataFrame(),pd.DataFrame()

for name,dataset in zip(["PA18","PA20","PA22","PA23","PA24"],[pa18,pa20,pa22,pa23,pa24]):

  cols=sensor.columns.tolist()

  newcols=[]
  for i in range(len(cols)):
      if name in cols[i]:
          newcols.append(cols[i])

  dataset=sensor[newcols]

  cols=dataset.columns.tolist()
  newcols=[]
  for i in range(len(cols)):
      if '# Date and time' not in cols[i]:
          newcols.append(cols[i][7:])

  dataset.columns=newcols

  dataset.insert(0, "Turbine", name)

  dataset.dropna(axis=1, how='all', inplace=True)
"""

#pa18

cols=sensor.columns.tolist()

newcols=[]
for i in range(len(cols)):
    if "PA18" in cols[i]:
        newcols.append(cols[i])

pa18=sensor[newcols]

cols=pa18.columns.tolist()
newcols=[]
for i in range(len(cols)):
    if '# Date and time' not in cols[i]:
        newcols.append(cols[i][7:])

pa18.columns=newcols

pa18.insert(0, "Turbine", "PA18")

pa18.dropna(axis=1, how='all', inplace=True)

#pa20

cols=sensor.columns.tolist()

newcols=[]

for i in range(len(cols)):
    if "PA20" in cols[i]:
        newcols.append(cols[i])

pa20=sensor[newcols]

cols=pa20.columns.tolist()

newcols=[]
for i in range(len(cols)):
    if '# Date and time' not in cols[i]:
        newcols.append(cols[i][7:])

pa20.columns=newcols

pa20.insert(0, "Turbine", "PA20")

pa20.dropna(axis=1, how='all', inplace=True)

#pa22

cols=sensor.columns.tolist()

newcols=[]

for i in range(len(cols)):
    if "PA22" in cols[i]:
        newcols.append(cols[i])

pa22=sensor[newcols]

cols=pa22.columns.tolist()

newcols=[]
for i in range(len(cols)):
    if '# Date and time' not in cols[i]:
        newcols.append(cols[i][7:])

pa22.columns=newcols

pa22.insert(0, "Turbine", "PA22")

pa22.dropna(axis=1, how='all', inplace=True)

#pa23

cols=sensor.columns.tolist()

newcols=[]

for i in range(len(cols)):
    if "PA23" in cols[i]:
        newcols.append(cols[i])

pa23=sensor[newcols]

cols=pa23.columns.tolist()

newcols=[]
for i in range(len(cols)):
    if '# Date and time' not in cols[i]:
        newcols.append(cols[i][7:])

pa23.columns=newcols

pa23.insert(0, "Turbine", "PA23")

pa23.dropna(axis=1, how='all', inplace=True)

#pa24

cols=sensor.columns.tolist()

newcols=[]

for i in range(len(cols)):
    if "PA24" in cols[i]:
        newcols.append(cols[i])

pa24=sensor[newcols]

cols=pa24.columns.tolist()

newcols=[]
for i in range(len(cols)):
    if '# Date and time' not in cols[i]:
        newcols.append(cols[i][7:])

pa24.columns=newcols

pa24.insert(0, "Turbine", "PA24")

pa24.dropna(axis=1, how='all', inplace=True)

df["Timestamp start"]=pd.to_datetime(df["Timestamp start"])
df.index=pd.to_datetime(df['Timestamp start'])

#pa18 errors

errors_pa18=df[(df["Turbine"]=="PA18")]

for i in range(len(errors_pa18)):
    if errors_pa18["Duration"][i]== "-":
        errors_pa18["Duration"][i]=0

dur=[]
for i in range(len(errors_pa18)):
    td = to_seconds(errors_pa18["Duration"][i], strict=False)
    td=td/60
    dur.append(td)

errors_pa18["Duration_Minutes"]=dur

tm=errors_pa18.index[1]
tm = tm - datetime.timedelta(minutes=tm.minute % 10,
                             seconds=tm.second,
                             microseconds=tm.microsecond)
tm

new_index=[]
for i in range(len(errors_pa18)):
    tm = errors_pa18.index[i] - datetime.timedelta(minutes=errors_pa18.index[i].minute % 10,
                             seconds=errors_pa18.index[i].second,
                             microseconds=errors_pa18.index[i].microsecond)
    new_index.append(tm)

errors_pa18.index=new_index


errors_pa18.drop(["Turbine"], axis=1, inplace=True)

data=pd.merge(left=pa18, right=errors_pa18, how="left", left_index=True, right_index=True)

code_label=[]
for i in range(len(data)):
    if pd.isnull(data.Code[i]):
        code_label.append(0)
    else:
        code_label.append(1)

data["code_label"] = code_label

sum(data["code_label"])

#errors pa20

errors_pa18=df[(df["Turbine"]=="PA20")]

for i in range(len(errors_pa18)):
    if errors_pa18["Duration"][i]== "-":
        errors_pa18["Duration"][i]=0

dur=[]
for i in range(len(errors_pa18)):
    td = to_seconds(errors_pa18["Duration"][i], strict=False)
    td=td/60
    dur.append(td)

errors_pa18["Duration_Minutes"]=dur

tm=errors_pa18.index[1]
tm = tm - datetime.timedelta(minutes=tm.minute % 10,
                             seconds=tm.second,
                             microseconds=tm.microsecond)
tm

new_index=[]
for i in range(len(errors_pa18)):
    tm = errors_pa18.index[i] - datetime.timedelta(minutes=errors_pa18.index[i].minute % 10,
                             seconds=errors_pa18.index[i].second,
                             microseconds=errors_pa18.index[i].microsecond)
    new_index.append(tm)

errors_pa18.index=new_index

errors_pa18.drop(["Turbine"], axis=1, inplace=True)

data20=pd.merge(left=pa20, right=errors_pa18, how="left", left_index=True, right_index=True)

code_label=[]
for i in range(len(data20)):
    if pd.isnull(data20.Code[i]):
        code_label.append(0)
    else:
        code_label.append(1)

data20["code_label"] = code_label

#errors pa22

errors_pa18=df[(df["Turbine"]=="PA22")]

for i in range(len(errors_pa18)):
    if errors_pa18["Duration"][i]== "-":
        errors_pa18["Duration"][i]=0

dur=[]
for i in range(len(errors_pa18)):
    td = to_seconds(errors_pa18["Duration"][i], strict=False)
    td=td/60
    dur.append(td)

errors_pa18["Duration_Minutes"]=dur

tm=errors_pa18.index[1]
tm = tm - datetime.timedelta(minutes=tm.minute % 10,
                             seconds=tm.second,
                             microseconds=tm.microsecond)
tm

new_index=[]
for i in range(len(errors_pa18)):
    tm = errors_pa18.index[i] - datetime.timedelta(minutes=errors_pa18.index[i].minute % 10,
                             seconds=errors_pa18.index[i].second,
                             microseconds=errors_pa18.index[i].microsecond)
    new_index.append(tm)

errors_pa18.index=new_index

errors_pa18.drop(["Turbine"], axis=1, inplace=True)

data22=pd.merge(left=pa22, right=errors_pa18, how="left", left_index=True, right_index=True)

code_label=[]
for i in range(len(data22)):
    if pd.isnull(data22.Code[i]):
        code_label.append(0)
    else:
        code_label.append(1)

data22["code_label"] = code_label

#errors pa23

errors_pa18=df[(df["Turbine"]=="PA23")]

for i in range(len(errors_pa18)):
    if errors_pa18["Duration"][i]== "-":
        errors_pa18["Duration"][i]=0

dur=[]
for i in range(len(errors_pa18)):
    td = to_seconds(errors_pa18["Duration"][i], strict=False)
    td=td/60
    dur.append(td)

errors_pa18["Duration_Minutes"]=dur

tm=errors_pa18.index[1]
tm = tm - datetime.timedelta(minutes=tm.minute % 10,
                             seconds=tm.second,
                             microseconds=tm.microsecond)
tm

new_index=[]
for i in range(len(errors_pa18)):
    tm = errors_pa18.index[i] - datetime.timedelta(minutes=errors_pa18.index[i].minute % 10,
                             seconds=errors_pa18.index[i].second,
                             microseconds=errors_pa18.index[i].microsecond)
    new_index.append(tm)

errors_pa18.index=new_index

errors_pa18.drop(["Turbine"], axis=1, inplace=True)

data23=pd.merge(left=pa23, right=errors_pa18, how="left", left_index=True, right_index=True)

code_label=[]
for i in range(len(data23)):
    if pd.isnull(data23.Code[i]):
        code_label.append(0)
    else:
        code_label.append(1)

data23["code_label"] = code_label

#errors pa24

errors_pa18=df[(df["Turbine"]=="PA24")]

for i in range(len(errors_pa18)):
    if errors_pa18["Duration"][i]== "-":
        errors_pa18["Duration"][i]=0

dur=[]
for i in range(len(errors_pa18)):
    td = to_seconds(errors_pa18["Duration"][i], strict=False)
    td=td/60
    dur.append(td)

errors_pa18["Duration_Minutes"]=dur

tm=errors_pa18.index[1]
tm = tm - datetime.timedelta(minutes=tm.minute % 10,
                             seconds=tm.second,
                             microseconds=tm.microsecond)
tm

new_index=[]
for i in range(len(errors_pa18)):
    tm = errors_pa18.index[i] - datetime.timedelta(minutes=errors_pa18.index[i].minute % 10,
                             seconds=errors_pa18.index[i].second,
                             microseconds=errors_pa18.index[i].microsecond)
    new_index.append(tm)

errors_pa18.index=new_index

errors_pa18.drop(["Turbine"], axis=1, inplace=True)

data24=pd.merge(left=pa24, right=errors_pa18, how="left", left_index=True, right_index=True)

code_label=[]
for i in range(len(data24)):
    if pd.isnull(data24.Code[i]):
        code_label.append(0)
    else:
        code_label.append(1)

data24["code_label"] = code_label

#stacking all datasets

finaldata=data.append(data20)

finaldata=finaldata.append(data22)

finaldata=finaldata.append(data23)

finaldata=finaldata.append(data24)

data=finaldata

data

#replace #CHAMP!

data=data.replace('#CHAMP!',np.NaN)

change_dtype=["Lost Production Total (kWh)","Power (kW)","Reactive power (kvar)","Energy Export (kWh)"]
for col in change_dtype:
  data[col] = data[col].astype("float")

#deletion of highly correlated columns

cols_to_drop = ["Grid busbar temperature (°C)",
                "Generator bearing front temperature (°C)",
                "Rotor inverter temperature L2 (°C)",
                "Rotor inverter temperature L3 (°C)",
                "Rotor speed (RPM)",
                "Gear bearing temp. (°C)",
                "Generator phase 1 temp (°C)",
                "Generator phase 2 temp (°C)",
                "Generator phase 3 temp (°C)", 
                "Power (kW)",
                "Current L1 / U (A)",
                "Current L2 / V (A)",
                "Current L3 / W (A)",
                "Wind speed, Minimum (m/s)",
                "Wind speed, Maximum (m/s)",
                "Voltage L1 / U (V)",
                "Voltage L2 / V (V)",
                "Nacelle position (°)",
                "Hub controller temp. (°C)",
                "Hub controller temp, (°C)",
                "Nacelle temperature (°C)",
                "Spinner temperature (°C)"]

data.drop(cols_to_drop,axis=1,inplace=True)

#Countdown

countdown=[]

for turbine in data.Turbine.unique()[::-1]:
  counter=0
  for Code,Status in zip(data[data.Turbine==turbine].Code[::-1],data[data.Turbine==turbine].Status[::-1]):
      if Code>0 and Code!=900 and Status=="Stop":
        counter=0
        countdown.append(counter)
      else:
        counter=counter+10
        countdown.append(counter)

data["Countdown"]=countdown[::-1]

#create extra-feature based on Garniche-Mining

counter=0
prev_code=[]

for i,j in zip(data.Code,data.Countdown):
  if i in [386, 172, 71, 72, 1014]:
    counter=counter+1
    prev_code.append(counter)
  elif j == 0:
    counter=0
    prev_code.append(counter)
  else:
    prev_code.append(counter)

data.insert(len(data.columns)-1,"Previous Codes",prev_code)
data["Previous Codes"] = data["Previous Codes"].astype("float")

#standardization, fill NAs

to_standardize=[]
for col in data.columns:
  if data[col].dtype=="float" and col!="Code":
    to_standardize.append(col)

data[to_standardize]=data[to_standardize].fillna(data[to_standardize].mean())

scaler=StandardScaler()
data[to_standardize] = scaler.fit_transform(data[to_standardize])

#fork data for classification

classification_data=data
classification_data.to_csv('/content/drive/My Drive/Remote Hacking/classification_data.csv',sep=";")

#building IDs

ID=[]
counter=1
for c in data.Countdown:
  if c!=0:
    ID.append(counter)
  if c==0:
    ID.append(counter)
    counter=counter+1
data.insert(0,"ID",ID)

#inserting an extra index-column

data.insert(0,"Index",range(0,len(data)))

#windows between errors

windows=[]
for id in data.ID.unique():
  windows.append(len(data[data.ID==id]))

ID_windows={}
for id,w in zip(data.ID.unique(),windows):
  ID_windows[id]=w

#IDs with sufficient cycle-length

week_instances=[]
for key in ID_windows.keys():
  if ID_windows[key]>1008:
    week_instances.append(key)

#only keep instances with two weeks cycle-length

data=data.loc[data.ID.isin(week_instances)]

#reduce observation-time frame

data = data[data.Countdown<=10080]
data.reset_index(inplace=True)

#fine-tune observation-time frame
data = data.drop(data[(data['ID'] == 410) & (data['Turbine'] == "PA20")].index)
data = data.drop(data[(data['ID'] == 882) & (data['Turbine'] == "PA20")].index)
data = data.drop(data[(data['ID'] == 1065) & (data['Turbine'] == "PA22")].index)
data = data.drop(data[data['ID'] == 1642].index)

#create NN-label

data['NN_label'] = np.where(data.Countdown <= 4320, 1, 0 )

#drop columns after index-setting

data.drop(["index","Index",
           "Timestamp start","Timestamp end","Duration","Status","Code","Message","Comment","Duration_Minutes","code_label"],
          axis=1,inplace=True,errors="ignore")

#save NN-data

NN_data = data
NN_data.to_csv('/content/drive/My Drive/Remote Hacking/NN_data_v2.csv',sep=";")

data.NN_label.value_counts()